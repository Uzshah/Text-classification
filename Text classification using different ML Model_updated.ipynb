{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # standard library for array processing\n",
    "import pandas as pd # standard library for deal with csv, excel and dataframe\n",
    "import nltk # natural langauge processing toolkit for deal with  natural langauge \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re # for string and expression\n",
    "from sklearn.model_selection import train_test_split # for split data\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer # convert language to machine understand langauge \n",
    "import h2o # machine learning library for auto finding best parameters and machine learning algorithm\n",
    "from h2o.automl import H2OAutoML \n",
    "from matplotlib import pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>original_title</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewers</th>\n",
       "      <th>category</th>\n",
       "      <th>tags</th>\n",
       "      <th>source_link</th>\n",
       "      <th>summary</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 4401</th>\n",
       "      <th>Unnamed: 4402</th>\n",
       "      <th>Unnamed: 4403</th>\n",
       "      <th>Unnamed: 4404</th>\n",
       "      <th>Unnamed: 4405</th>\n",
       "      <th>Unnamed: 4406</th>\n",
       "      <th>Unnamed: 4407</th>\n",
       "      <th>Unnamed: 4408</th>\n",
       "      <th>Unnamed: 4409</th>\n",
       "      <th>Unnamed: 4410</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.healthnewsreview.org/review/guardi...</td>\n",
       "      <td>Guardian jumps to conclusions about an Alzheim...</td>\n",
       "      <td>The storyâ€™s headline states: â€œVirtual real...</td>\n",
       "      <td>Virtual reality to help detect early risk of A...</td>\n",
       "      <td>1</td>\n",
       "      <td>['Matt Shipman', 'Doug Campos-Outcalt, MD, MPA...</td>\n",
       "      <td>The Guardian</td>\n",
       "      <td>[\"alzheimer's disease\"]</td>\n",
       "      <td>https://www.theguardian.com/society/2018/dec/1...</td>\n",
       "      <td>{'Our Review Summary': 'The story focuses on a...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.healthnewsreview.org/review/in-sto...</td>\n",
       "      <td>In story on experimental contraceptive gel, Re...</td>\n",
       "      <td>This leaves both investors and lay audiences w...</td>\n",
       "      <td>Evofem's birth control gel meets main study go...</td>\n",
       "      <td>3</td>\n",
       "      <td>['Jill U. Adams', 'Susan Molchan, MD, MA', 'Jo...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>['contraceptives']</td>\n",
       "      <td>https://www.reuters.com/article/us-evofem-stud...</td>\n",
       "      <td>{'Our Review Summary': 'Reuters reports on a n...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.healthnewsreview.org/review/using-...</td>\n",
       "      <td>Using a single patient anecdote, ABC News hail...</td>\n",
       "      <td>Breakthrough? Based on the story of one patien...</td>\n",
       "      <td>How a breakthrough new fertility test is offer...</td>\n",
       "      <td>2</td>\n",
       "      <td>['Gary Schwitzer', 'Karen Carlson, MD', 'Joy V...</td>\n",
       "      <td>ABC News</td>\n",
       "      <td>['infertility']</td>\n",
       "      <td>https://abcnews.go.com/GMA/Wellness/breakthrou...</td>\n",
       "      <td>{'Our Review Summary': 'ABC News pursues a sto...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.healthnewsreview.org/review/hard-t...</td>\n",
       "      <td>Hard to find the journalism in this brief Reut...</td>\n",
       "      <td>The story mostly just rehashes a drug company ...</td>\n",
       "      <td>J&amp;J says its psoriasis drug superior to Novart...</td>\n",
       "      <td>2</td>\n",
       "      <td>['Michael Joyce, MD', 'Ishani Ganguli, MD, MPH...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>['Psoriasis']</td>\n",
       "      <td>https://www.reuters.com/article/us-j-j-drug-ps...</td>\n",
       "      <td>{'Our Review Summary': 'This is a brief news s...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.healthnewsreview.org/review/a-litt...</td>\n",
       "      <td>A little more context would have boosted alrea...</td>\n",
       "      <td>Did the study findings really earn a label of ...</td>\n",
       "      <td>Incontinence Drug May Cut Hot Flashes in Brea...</td>\n",
       "      <td>5</td>\n",
       "      <td>['Sue Rochman', 'Karen Carlson, MD', 'Joy Vict...</td>\n",
       "      <td>HealthDay</td>\n",
       "      <td>['breast cancer', 'hot flashes']</td>\n",
       "      <td>https://consumer.healthday.com/women-s-health-...</td>\n",
       "      <td>{'Our Review Summary': 'The San Antonio Breast...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4411 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  https://www.healthnewsreview.org/review/guardi...   \n",
       "1  https://www.healthnewsreview.org/review/in-sto...   \n",
       "2  https://www.healthnewsreview.org/review/using-...   \n",
       "3  https://www.healthnewsreview.org/review/hard-t...   \n",
       "4  https://www.healthnewsreview.org/review/a-litt...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Guardian jumps to conclusions about an Alzheim...   \n",
       "1  In story on experimental contraceptive gel, Re...   \n",
       "2  Using a single patient anecdote, ABC News hail...   \n",
       "3  Hard to find the journalism in this brief Reut...   \n",
       "4  A little more context would have boosted alrea...   \n",
       "\n",
       "                                         description  \\\n",
       "0  The storyâ€™s headline states: â€œVirtual real...   \n",
       "1  This leaves both investors and lay audiences w...   \n",
       "2  Breakthrough? Based on the story of one patien...   \n",
       "3  The story mostly just rehashes a drug company ...   \n",
       "4  Did the study findings really earn a label of ...   \n",
       "\n",
       "                                      original_title  rating  \\\n",
       "0  Virtual reality to help detect early risk of A...       1   \n",
       "1  Evofem's birth control gel meets main study go...       3   \n",
       "2  How a breakthrough new fertility test is offer...       2   \n",
       "3  J&J says its psoriasis drug superior to Novart...       2   \n",
       "4   Incontinence Drug May Cut Hot Flashes in Brea...       5   \n",
       "\n",
       "                                           reviewers      category  \\\n",
       "0  ['Matt Shipman', 'Doug Campos-Outcalt, MD, MPA...  The Guardian   \n",
       "1  ['Jill U. Adams', 'Susan Molchan, MD, MA', 'Jo...       Reuters   \n",
       "2  ['Gary Schwitzer', 'Karen Carlson, MD', 'Joy V...      ABC News   \n",
       "3  ['Michael Joyce, MD', 'Ishani Ganguli, MD, MPH...       Reuters   \n",
       "4  ['Sue Rochman', 'Karen Carlson, MD', 'Joy Vict...     HealthDay   \n",
       "\n",
       "                               tags  \\\n",
       "0           [\"alzheimer's disease\"]   \n",
       "1                ['contraceptives']   \n",
       "2                   ['infertility']   \n",
       "3                     ['Psoriasis']   \n",
       "4  ['breast cancer', 'hot flashes']   \n",
       "\n",
       "                                         source_link  \\\n",
       "0  https://www.theguardian.com/society/2018/dec/1...   \n",
       "1  https://www.reuters.com/article/us-evofem-stud...   \n",
       "2  https://abcnews.go.com/GMA/Wellness/breakthrou...   \n",
       "3  https://www.reuters.com/article/us-j-j-drug-ps...   \n",
       "4  https://consumer.healthday.com/women-s-health-...   \n",
       "\n",
       "                                             summary  ... Unnamed: 4401  \\\n",
       "0  {'Our Review Summary': 'The story focuses on a...  ...           NaN   \n",
       "1  {'Our Review Summary': 'Reuters reports on a n...  ...           NaN   \n",
       "2  {'Our Review Summary': 'ABC News pursues a sto...  ...           NaN   \n",
       "3  {'Our Review Summary': 'This is a brief news s...  ...           NaN   \n",
       "4  {'Our Review Summary': 'The San Antonio Breast...  ...           NaN   \n",
       "\n",
       "  Unnamed: 4402 Unnamed: 4403 Unnamed: 4404 Unnamed: 4405 Unnamed: 4406  \\\n",
       "0           NaN           NaN           NaN           NaN           NaN   \n",
       "1           NaN           NaN           NaN           NaN           NaN   \n",
       "2           NaN           NaN           NaN           NaN           NaN   \n",
       "3           NaN           NaN           NaN           NaN           NaN   \n",
       "4           NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "  Unnamed: 4407 Unnamed: 4408 Unnamed: 4409 Unnamed: 4410  \n",
       "0           NaN           NaN           NaN           NaN  \n",
       "1           NaN           NaN           NaN           NaN  \n",
       "2           NaN           NaN           NaN           NaN  \n",
       "3           NaN           NaN           NaN           NaN  \n",
       "4           NaN           NaN           NaN           NaN  \n",
       "\n",
       "[5 rows x 4411 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('HealthStoryCSVFileContainingAllData.xlsx') # read the data and save in df \n",
    "df.head() # display some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is a lot of columns so we pick only our target columns\n",
    "df_ = df[['text','Q6']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the empty text column rows\n",
    "df_.dropna(subset=['text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the nan values in text\n",
    "df_['text'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clean the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we define functions for clean the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_remove_words_less_then_3(text):\n",
    "    text = text.split()\n",
    "    text = \" \".join([word for word in text if len(word)>2])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "def nltk_stopword(text, stpwrd=stop_words):\n",
    "    text = text.split()\n",
    "    text = \" \".join([word.lower() for word in text if not word in stpwrd])\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "def stemming_func(text):\n",
    "    text = text.split()\n",
    "    text = \" \".join([ps.stem(word) for word in text])\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ushah/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "def remove_punc(text):\n",
    "    text = text.split()\n",
    "    text = \" \".join([word for word in text if word.isalnum()])\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_['text'] = df_['text'].map(lambda x: str(x))\n",
    "df_['text'] = df_['text'].apply(list_to_remove_words_less_then_3)\n",
    "df_['text'] = df_['text'].apply(nltk_stopword)\n",
    "df_['text'] = df_['text'].apply(remove_punc)\n",
    "df_['text'] = df_['text'].apply(stemming_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the functions to clean the text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df_[df_['Q6'].isin(['Not Satisfactory', 'Satisfactory', 'Not Applicable'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_.Q6.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding for target column\n",
    "encoding = {'Not Satisfactory': 0,\n",
    "            'Not Applicable': 0,\n",
    "            'Satisfactory': 1,\n",
    "           }\n",
    "\n",
    "labels = ['Not Satisfactory', 'Satisfactory']\n",
    "           \n",
    "\n",
    "df_['Q6'].replace(encoding, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.dropna(subset = [\"text\"], inplace=True)\n",
    "df_.text.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform each text into a vector of word counts\n",
    "vectorizer = CountVectorizer(max_features=2000, max_df = 0.75, \n",
    "                             input=df_['text'].all(),\n",
    "                            ngram_range=(1,2))\n",
    "\n",
    "training_features = vectorizer.fit_transform(df_['text']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(training_features.A, df_['Q6'], test_size = 0.15, \n",
    "                                                    random_state = 101, stratify=df_.Q6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  80.0\n",
      "[0.58823529 0.59191176 0.67279412 0.62132353 0.65808824]\n",
      "0.6264705882352942\n",
      "\n",
      "\n",
      "alpha:  90.0\n",
      "[0.58823529 0.59926471 0.67647059 0.62132353 0.67279412]\n",
      "0.6316176470588235\n",
      "\n",
      "\n",
      "alpha:  100.0\n",
      "[0.58823529 0.58823529 0.67647059 0.63602941 0.66911765]\n",
      "0.6316176470588235\n",
      "\n",
      "\n",
      "alpha:  110.0\n",
      "[0.58823529 0.59191176 0.67647059 0.63970588 0.66544118]\n",
      "0.6323529411764706\n",
      "\n",
      "\n",
      "alpha:  120.0\n",
      "[0.58823529 0.60661765 0.67279412 0.63970588 0.66544118]\n",
      "0.6345588235294117\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn\n",
    "alpha = [80.0, 90.0, 100.0, 110.0, 120.0] \n",
    "for a in alpha:\n",
    "    ridge = linear_model.RidgeClassifier(a)\n",
    "    scores = sklearn.model_selection.cross_val_score(ridge, x_train, y_train, cv=5)#scoring='f1' kaldirdim multiclass hatasina karsilik\n",
    "    print(\"alpha: \",a)\n",
    "    print(scores)\n",
    "    print(np.mean(scores))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  1e-10\n",
      "[0.58823529 0.56617647 0.65441176 0.56985294 0.55882353]\n",
      "0.5875\n",
      "\n",
      "\n",
      "alpha:  1e-05\n",
      "[0.58823529 0.56617647 0.65441176 0.56985294 0.55882353]\n",
      "0.5875\n",
      "\n",
      "\n",
      "alpha:  0.1\n",
      "[0.58823529 0.56985294 0.65073529 0.57720588 0.55882353]\n",
      "0.5889705882352942\n",
      "\n",
      "\n",
      "alpha:  1.0\n",
      "[0.58088235 0.56985294 0.65073529 0.58088235 0.55882353]\n",
      "0.5882352941176471\n",
      "\n",
      "\n",
      "alpha:  2.0\n",
      "[0.58455882 0.56617647 0.64338235 0.58823529 0.55882353]\n",
      "0.5882352941176471\n",
      "\n",
      "\n",
      "alpha:  5.0\n",
      "[0.58088235 0.55514706 0.66544118 0.59558824 0.56617647]\n",
      "0.5926470588235295\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MultinomialNB with bag of word\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "alpha = [1e-10, 1e-5, 0.1, 1.0, 2.0, 5.0]\n",
    "for a in alpha:\n",
    "    mnb = MultinomialNB(a)\n",
    "    scores = sklearn.model_selection.cross_val_score(mnb, x_train, y_train, cv=5)\n",
    "    print('alpha: ', a)\n",
    "    print(scores)\n",
    "    print(np.mean(scores))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.62      0.57       118\n",
      "           1       0.57      0.49      0.53       123\n",
      "\n",
      "    accuracy                           0.55       241\n",
      "   macro avg       0.55      0.55      0.55       241\n",
      "weighted avg       0.55      0.55      0.55       241\n",
      "\n",
      "[[73 45]\n",
      " [63 60]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "dtclassifier=DecisionTreeClassifier(criterion=\"entropy\", max_depth=None)\n",
    "dtclassifier.fit(x_train,y_train)\n",
    "preddt = dtclassifier.predict(x_test)\n",
    "accuracy= accuracy_score(preddt,y_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test, preddt))\n",
    "print(confusion_matrix(y_test, preddt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.62      0.59       118\n",
      "           1       0.59      0.54      0.56       123\n",
      "\n",
      "    accuracy                           0.58       241\n",
      "   macro avg       0.58      0.58      0.58       241\n",
      "weighted avg       0.58      0.58      0.58       241\n",
      "\n",
      "[[73 45]\n",
      " [57 66]]\n"
     ]
    }
   ],
   "source": [
    "# Perform classification with SVM, kernel=linear\n",
    "import time\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "classifier_linear = svm.SVC(kernel='linear')\n",
    "classifier_linear.fit(x_train, y_train)\n",
    "prediction_linear = classifier_linear.predict(x_test)\n",
    "print(classification_report(y_test, prediction_linear))\n",
    "print(confusion_matrix(y_test, prediction_linear))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ushah/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.68      0.63       118\n",
      "           1       0.63      0.54      0.58       123\n",
      "\n",
      "    accuracy                           0.61       241\n",
      "   macro avg       0.61      0.61      0.60       241\n",
      "weighted avg       0.61      0.61      0.60       241\n",
      "\n",
      "[[80 38]\n",
      " [57 66]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression(solver='lbfgs', multi_class=\"ovr\")\n",
    "log_reg.fit(x_train, y_train)\n",
    "prediction_linear = log_reg.predict(x_test)\n",
    "print(classification_report(y_test, prediction_linear))\n",
    "print(confusion_matrix(y_test, prediction_linear))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.62      0.65       118\n",
      "           1       0.66      0.72      0.69       123\n",
      "\n",
      "    accuracy                           0.67       241\n",
      "   macro avg       0.67      0.67      0.67       241\n",
      "weighted avg       0.67      0.67      0.67       241\n",
      "\n",
      "[[73 45]\n",
      " [35 88]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rnf = RandomForestClassifier(n_estimators=200)\n",
    "rnf.fit(x_train, y_train)\n",
    "prediction_linear = rnf.predict(x_test)\n",
    "print(classification_report(y_test, prediction_linear))\n",
    "print(confusion_matrix(y_test, prediction_linear))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.65      0.64       118\n",
      "           1       0.66      0.63      0.64       123\n",
      "\n",
      "    accuracy                           0.64       241\n",
      "   macro avg       0.64      0.64      0.64       241\n",
      "weighted avg       0.64      0.64      0.64       241\n",
      "\n",
      "[[77 41]\n",
      " [45 78]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier(n_estimators=400, random_state = 2020)\n",
    "gbc.fit(x_train, y_train)\n",
    "prediction_linear = gbc.predict(x_test)\n",
    "print(classification_report(y_test, prediction_linear))\n",
    "print(confusion_matrix(y_test, prediction_linear))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.65      0.63       118\n",
      "           1       0.64      0.60      0.62       123\n",
      "\n",
      "    accuracy                           0.63       241\n",
      "   macro avg       0.63      0.63      0.63       241\n",
      "weighted avg       0.63      0.63      0.63       241\n",
      "\n",
      "[[77 41]\n",
      " [49 74]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "hgbc = HistGradientBoostingClassifier()\n",
    "hgbc.fit(x_train, y_train)\n",
    "prediction_linear = hgbc.predict(x_test)\n",
    "print(classification_report(y_test, prediction_linear))\n",
    "print(confusion_matrix(y_test, prediction_linear))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply MinMaxScaler on countvectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_train = min_max_scaler.fit_transform(x_train)\n",
    "x_test = min_max_scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  80.0\n",
      "[0.67279412 0.68014706 0.67647059 0.63602941 0.69117647]\n",
      "0.6713235294117647\n",
      "\n",
      "\n",
      "alpha:  90.0\n",
      "[0.66911765 0.68382353 0.67279412 0.63970588 0.69117647]\n",
      "0.6713235294117647\n",
      "\n",
      "\n",
      "alpha:  100.0\n",
      "[0.66911765 0.68014706 0.66176471 0.64338235 0.6875    ]\n",
      "0.6683823529411764\n",
      "\n",
      "\n",
      "alpha:  110.0\n",
      "[0.66544118 0.68014706 0.68014706 0.65073529 0.6875    ]\n",
      "0.6727941176470589\n",
      "\n",
      "\n",
      "alpha:  120.0\n",
      "[0.66911765 0.68014706 0.67647059 0.64705882 0.69117647]\n",
      "0.6727941176470587\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn\n",
    "alpha = [80.0, 90.0, 100.0, 110.0, 120.0] \n",
    "for a in alpha:\n",
    "    ridge = linear_model.RidgeClassifier(a)\n",
    "    scores = sklearn.model_selection.cross_val_score(ridge, x_train, y_train, cv=5)#scoring='f1' kaldirdim multiclass hatasina karsilik\n",
    "    print(\"alpha: \",a)\n",
    "    print(scores)\n",
    "    print(np.mean(scores))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  1e-10\n",
      "[0.60294118 0.59926471 0.64705882 0.63602941 0.60661765]\n",
      "0.6183823529411765\n",
      "\n",
      "\n",
      "alpha:  1e-05\n",
      "[0.60294118 0.59926471 0.64705882 0.63602941 0.60661765]\n",
      "0.6183823529411765\n",
      "\n",
      "\n",
      "alpha:  0.1\n",
      "[0.59926471 0.59926471 0.64705882 0.625      0.59558824]\n",
      "0.6132352941176471\n",
      "\n",
      "\n",
      "alpha:  1.0\n",
      "[0.61029412 0.59191176 0.63602941 0.60294118 0.60294118]\n",
      "0.6088235294117647\n",
      "\n",
      "\n",
      "alpha:  2.0\n",
      "[0.59558824 0.60294118 0.63235294 0.60294118 0.59926471]\n",
      "0.6066176470588235\n",
      "\n",
      "\n",
      "alpha:  5.0\n",
      "[0.59191176 0.61029412 0.66176471 0.60661765 0.60294118]\n",
      "0.6147058823529411\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MultinomialNB with bag of word\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "alpha = [1e-10, 1e-5, 0.1, 1.0, 2.0, 5.0]\n",
    "for a in alpha:\n",
    "    mnb = MultinomialNB(a)\n",
    "    scores = sklearn.model_selection.cross_val_score(mnb, x_train, y_train, cv=5)\n",
    "    print('alpha: ', a)\n",
    "    print(scores)\n",
    "    print(np.mean(scores))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.53      0.53       118\n",
      "           1       0.55      0.56      0.56       123\n",
      "\n",
      "    accuracy                           0.54       241\n",
      "   macro avg       0.54      0.54      0.54       241\n",
      "weighted avg       0.54      0.54      0.54       241\n",
      "\n",
      "[[62 56]\n",
      " [54 69]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "dtclassifier=DecisionTreeClassifier(criterion=\"entropy\", max_depth=None)\n",
    "dtclassifier.fit(x_train,y_train)\n",
    "preddt = dtclassifier.predict(x_test)\n",
    "accuracy= accuracy_score(preddt,y_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test, preddt))\n",
    "print(confusion_matrix(y_test, preddt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.49      0.51       118\n",
      "           1       0.55      0.59      0.56       123\n",
      "\n",
      "    accuracy                           0.54       241\n",
      "   macro avg       0.54      0.54      0.54       241\n",
      "weighted avg       0.54      0.54      0.54       241\n",
      "\n",
      "[[58 60]\n",
      " [51 72]]\n"
     ]
    }
   ],
   "source": [
    "# Perform classification with SVM, kernel=linear\n",
    "import time\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "classifier_linear = svm.SVC(kernel='linear')\n",
    "classifier_linear.fit(x_train, y_train)\n",
    "prediction_linear = classifier_linear.predict(x_test)\n",
    "print(classification_report(y_test, prediction_linear))\n",
    "print(confusion_matrix(y_test, prediction_linear))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.50      0.53       118\n",
      "           1       0.57      0.63      0.60       123\n",
      "\n",
      "    accuracy                           0.57       241\n",
      "   macro avg       0.57      0.57      0.57       241\n",
      "weighted avg       0.57      0.57      0.57       241\n",
      "\n",
      "[[59 59]\n",
      " [45 78]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression(solver='lbfgs', multi_class=\"ovr\")\n",
    "log_reg.fit(x_train, y_train)\n",
    "prediction_linear = log_reg.predict(x_test)\n",
    "print(classification_report(y_test, prediction_linear))\n",
    "print(confusion_matrix(y_test, prediction_linear))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.42      0.52       118\n",
      "           1       0.59      0.79      0.67       123\n",
      "\n",
      "    accuracy                           0.61       241\n",
      "   macro avg       0.62      0.61      0.59       241\n",
      "weighted avg       0.62      0.61      0.60       241\n",
      "\n",
      "[[50 68]\n",
      " [26 97]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rnf = RandomForestClassifier(n_estimators=400, random_state = 2020)\n",
    "rnf.fit(x_train, y_train)\n",
    "prediction_linear = rnf.predict(x_test)\n",
    "print(classification_report(y_test, prediction_linear))\n",
    "print(confusion_matrix(y_test, prediction_linear))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.67      0.64       118\n",
      "           1       0.66      0.61      0.63       123\n",
      "\n",
      "    accuracy                           0.64       241\n",
      "   macro avg       0.64      0.64      0.64       241\n",
      "weighted avg       0.64      0.64      0.64       241\n",
      "\n",
      "[[79 39]\n",
      " [48 75]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier(n_estimators=400, random_state = 2020)\n",
    "gbc.fit(x_train, y_train)\n",
    "prediction_linear = gbc.predict(x_test)\n",
    "print(classification_report(y_test, prediction_linear))\n",
    "print(confusion_matrix(y_test, prediction_linear))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.66      0.65       118\n",
      "           1       0.67      0.65      0.66       123\n",
      "\n",
      "    accuracy                           0.66       241\n",
      "   macro avg       0.66      0.66      0.66       241\n",
      "weighted avg       0.66      0.66      0.66       241\n",
      "\n",
      "[[78 40]\n",
      " [43 80]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "hgbc = HistGradientBoostingClassifier()\n",
    "hgbc.fit(x_train, y_train)\n",
    "prediction_linear = hgbc.predict(x_test)\n",
    "print(classification_report(y_test, prediction_linear))\n",
    "print(confusion_matrix(y_test, prediction_linear))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform each text into a vector of word counts\n",
    "vectorizer1 = TfidfVectorizer(max_features=2000, max_df = 0.75, \n",
    "                             input=df_['text'].all(),\n",
    "                            ngram_range=(1,2))\n",
    "\n",
    "training_features = vectorizer1.fit_transform(df_['text']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(training_features.A, df_['Q6'], test_size = 0.15, \n",
    "                                                    random_state = 101, stratify=df_.Q6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  80.0\n",
      "[0.54779412 0.61029412 0.62132353 0.54411765 0.56617647]\n",
      "0.5779411764705882\n",
      "\n",
      "\n",
      "alpha:  90.0\n",
      "[0.55882353 0.59191176 0.60661765 0.54411765 0.56617647]\n",
      "0.5735294117647058\n",
      "\n",
      "\n",
      "alpha:  100.0\n",
      "[0.55514706 0.58823529 0.58455882 0.54779412 0.55882353]\n",
      "0.5669117647058824\n",
      "\n",
      "\n",
      "alpha:  110.0\n",
      "[0.51838235 0.58088235 0.57720588 0.54779412 0.55147059]\n",
      "0.5551470588235295\n",
      "\n",
      "\n",
      "alpha:  120.0\n",
      "[0.51838235 0.57720588 0.57720588 0.55147059 0.5625    ]\n",
      "0.5573529411764706\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn\n",
    "alpha = [80.0, 90.0, 100.0, 110.0, 120.0] \n",
    "for a in alpha:\n",
    "    ridge = linear_model.RidgeClassifier(a)\n",
    "    scores = sklearn.model_selection.cross_val_score(ridge, x_train, y_train, cv=5)#scoring='f1' kaldirdim multiclass hatasina karsilik\n",
    "    print(\"alpha: \",a)\n",
    "    print(scores)\n",
    "    print(np.mean(scores))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  1e-10\n",
      "[0.58088235 0.59926471 0.63235294 0.55882353 0.55147059]\n",
      "0.5845588235294118\n",
      "\n",
      "\n",
      "alpha:  1e-05\n",
      "[0.58088235 0.59926471 0.63235294 0.55882353 0.55147059]\n",
      "0.5845588235294118\n",
      "\n",
      "\n",
      "alpha:  0.1\n",
      "[0.58088235 0.59926471 0.63235294 0.5625     0.54044118]\n",
      "0.5830882352941177\n",
      "\n",
      "\n",
      "alpha:  1.0\n",
      "[0.58088235 0.59926471 0.63602941 0.57720588 0.55147059]\n",
      "0.5889705882352942\n",
      "\n",
      "\n",
      "alpha:  2.0\n",
      "[0.55882353 0.58823529 0.63602941 0.57352941 0.55147059]\n",
      "0.5816176470588236\n",
      "\n",
      "\n",
      "alpha:  5.0\n",
      "[0.54779412 0.60661765 0.63970588 0.57720588 0.54411765]\n",
      "0.5830882352941176\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MultinomialNB with bag of word\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "alpha = [1e-10, 1e-5, 0.1, 1.0, 2.0, 5.0]\n",
    "for a in alpha:\n",
    "    mnb = MultinomialNB(a)\n",
    "    scores = sklearn.model_selection.cross_val_score(mnb, x_train, y_train, cv=5)\n",
    "    print('alpha: ', a)\n",
    "    print(scores)\n",
    "    print(np.mean(scores))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.58      0.54       118\n",
      "           1       0.52      0.45      0.48       123\n",
      "\n",
      "    accuracy                           0.51       241\n",
      "   macro avg       0.51      0.51      0.51       241\n",
      "weighted avg       0.51      0.51      0.51       241\n",
      "\n",
      "[[68 50]\n",
      " [68 55]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "dtclassifier=DecisionTreeClassifier(criterion=\"entropy\", max_depth=None)\n",
    "dtclassifier.fit(x_train,y_train)\n",
    "preddt = dtclassifier.predict(x_test)\n",
    "accuracy= accuracy_score(preddt,y_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test, preddt))\n",
    "print(confusion_matrix(y_test, preddt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.58      0.57       118\n",
      "           1       0.59      0.59      0.59       123\n",
      "\n",
      "    accuracy                           0.58       241\n",
      "   macro avg       0.58      0.58      0.58       241\n",
      "weighted avg       0.58      0.58      0.58       241\n",
      "\n",
      "[[68 50]\n",
      " [51 72]]\n"
     ]
    }
   ],
   "source": [
    "# Perform classification with SVM, kernel=linear\n",
    "import time\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "classifier_linear = svm.SVC(kernel='linear')\n",
    "classifier_linear.fit(x_train, y_train)\n",
    "prediction_linear = classifier_linear.predict(x_test)\n",
    "print(classification_report(y_test, prediction_linear))\n",
    "print(confusion_matrix(y_test, prediction_linear))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.58      0.57       118\n",
      "           1       0.58      0.56      0.57       123\n",
      "\n",
      "    accuracy                           0.57       241\n",
      "   macro avg       0.57      0.57      0.57       241\n",
      "weighted avg       0.57      0.57      0.57       241\n",
      "\n",
      "[[68 50]\n",
      " [54 69]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression(solver='lbfgs', multi_class=\"ovr\")\n",
    "log_reg.fit(x_train, y_train)\n",
    "prediction_linear = log_reg.predict(x_test)\n",
    "print(classification_report(y_test, prediction_linear))\n",
    "print(confusion_matrix(y_test, prediction_linear))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.60      0.60       118\n",
      "           1       0.62      0.63      0.62       123\n",
      "\n",
      "    accuracy                           0.61       241\n",
      "   macro avg       0.61      0.61      0.61       241\n",
      "weighted avg       0.61      0.61      0.61       241\n",
      "\n",
      "[[71 47]\n",
      " [46 77]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rnf = RandomForestClassifier(n_estimators=400, random_state = 2020)\n",
    "rnf.fit(x_train, y_train)\n",
    "prediction_linear = rnf.predict(x_test)\n",
    "print(classification_report(y_test, prediction_linear))\n",
    "print(confusion_matrix(y_test, prediction_linear))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.60      0.61       118\n",
      "           1       0.63      0.64      0.63       123\n",
      "\n",
      "    accuracy                           0.62       241\n",
      "   macro avg       0.62      0.62      0.62       241\n",
      "weighted avg       0.62      0.62      0.62       241\n",
      "\n",
      "[[71 47]\n",
      " [44 79]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier(n_estimators=400, random_state = 2020)\n",
    "gbc.fit(x_train, y_train)\n",
    "prediction_linear = gbc.predict(x_test)\n",
    "print(classification_report(y_test, prediction_linear))\n",
    "print(confusion_matrix(y_test, prediction_linear))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62       118\n",
      "           1       0.63      0.63      0.63       123\n",
      "\n",
      "    accuracy                           0.63       241\n",
      "   macro avg       0.63      0.63      0.63       241\n",
      "weighted avg       0.63      0.63      0.63       241\n",
      "\n",
      "[[73 45]\n",
      " [45 78]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "gbc = HistGradientBoostingClassifier()\n",
    "gbc.fit(x_train, y_train)\n",
    "prediction_linear = gbc.predict(x_test)\n",
    "print(classification_report(y_test, prediction_linear))\n",
    "print(confusion_matrix(y_test, prediction_linear))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
