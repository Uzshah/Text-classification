{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # standard library for array processing\n",
    "import pandas as pd # standard library for deal with csv, excel and dataframe\n",
    "import nltk # natural langauge processing toolkit for deal with  natural langauge \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re # for string and expression\n",
    "from sklearn.model_selection import train_test_split # for split data\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # convert language to machine understand langauge \n",
    "import h2o # machine learning library for auto finding best parameters and machine learning algorithm\n",
    "from h2o.automl import H2OAutoML \n",
    "from matplotlib import pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>original_title</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewers</th>\n",
       "      <th>category</th>\n",
       "      <th>tags</th>\n",
       "      <th>source_link</th>\n",
       "      <th>summary</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 4401</th>\n",
       "      <th>Unnamed: 4402</th>\n",
       "      <th>Unnamed: 4403</th>\n",
       "      <th>Unnamed: 4404</th>\n",
       "      <th>Unnamed: 4405</th>\n",
       "      <th>Unnamed: 4406</th>\n",
       "      <th>Unnamed: 4407</th>\n",
       "      <th>Unnamed: 4408</th>\n",
       "      <th>Unnamed: 4409</th>\n",
       "      <th>Unnamed: 4410</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.healthnewsreview.org/review/guardi...</td>\n",
       "      <td>Guardian jumps to conclusions about an Alzheim...</td>\n",
       "      <td>The storyâ€™s headline states: â€œVirtual real...</td>\n",
       "      <td>Virtual reality to help detect early risk of A...</td>\n",
       "      <td>1</td>\n",
       "      <td>['Matt Shipman', 'Doug Campos-Outcalt, MD, MPA...</td>\n",
       "      <td>The Guardian</td>\n",
       "      <td>[\"alzheimer's disease\"]</td>\n",
       "      <td>https://www.theguardian.com/society/2018/dec/1...</td>\n",
       "      <td>{'Our Review Summary': 'The story focuses on a...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.healthnewsreview.org/review/in-sto...</td>\n",
       "      <td>In story on experimental contraceptive gel, Re...</td>\n",
       "      <td>This leaves both investors and lay audiences w...</td>\n",
       "      <td>Evofem's birth control gel meets main study go...</td>\n",
       "      <td>3</td>\n",
       "      <td>['Jill U. Adams', 'Susan Molchan, MD, MA', 'Jo...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>['contraceptives']</td>\n",
       "      <td>https://www.reuters.com/article/us-evofem-stud...</td>\n",
       "      <td>{'Our Review Summary': 'Reuters reports on a n...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.healthnewsreview.org/review/using-...</td>\n",
       "      <td>Using a single patient anecdote, ABC News hail...</td>\n",
       "      <td>Breakthrough? Based on the story of one patien...</td>\n",
       "      <td>How a breakthrough new fertility test is offer...</td>\n",
       "      <td>2</td>\n",
       "      <td>['Gary Schwitzer', 'Karen Carlson, MD', 'Joy V...</td>\n",
       "      <td>ABC News</td>\n",
       "      <td>['infertility']</td>\n",
       "      <td>https://abcnews.go.com/GMA/Wellness/breakthrou...</td>\n",
       "      <td>{'Our Review Summary': 'ABC News pursues a sto...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.healthnewsreview.org/review/hard-t...</td>\n",
       "      <td>Hard to find the journalism in this brief Reut...</td>\n",
       "      <td>The story mostly just rehashes a drug company ...</td>\n",
       "      <td>J&amp;J says its psoriasis drug superior to Novart...</td>\n",
       "      <td>2</td>\n",
       "      <td>['Michael Joyce, MD', 'Ishani Ganguli, MD, MPH...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>['Psoriasis']</td>\n",
       "      <td>https://www.reuters.com/article/us-j-j-drug-ps...</td>\n",
       "      <td>{'Our Review Summary': 'This is a brief news s...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.healthnewsreview.org/review/a-litt...</td>\n",
       "      <td>A little more context would have boosted alrea...</td>\n",
       "      <td>Did the study findings really earn a label of ...</td>\n",
       "      <td>Incontinence Drug May Cut Hot Flashes in Brea...</td>\n",
       "      <td>5</td>\n",
       "      <td>['Sue Rochman', 'Karen Carlson, MD', 'Joy Vict...</td>\n",
       "      <td>HealthDay</td>\n",
       "      <td>['breast cancer', 'hot flashes']</td>\n",
       "      <td>https://consumer.healthday.com/women-s-health-...</td>\n",
       "      <td>{'Our Review Summary': 'The San Antonio Breast...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4411 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  https://www.healthnewsreview.org/review/guardi...   \n",
       "1  https://www.healthnewsreview.org/review/in-sto...   \n",
       "2  https://www.healthnewsreview.org/review/using-...   \n",
       "3  https://www.healthnewsreview.org/review/hard-t...   \n",
       "4  https://www.healthnewsreview.org/review/a-litt...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Guardian jumps to conclusions about an Alzheim...   \n",
       "1  In story on experimental contraceptive gel, Re...   \n",
       "2  Using a single patient anecdote, ABC News hail...   \n",
       "3  Hard to find the journalism in this brief Reut...   \n",
       "4  A little more context would have boosted alrea...   \n",
       "\n",
       "                                         description  \\\n",
       "0  The storyâ€™s headline states: â€œVirtual real...   \n",
       "1  This leaves both investors and lay audiences w...   \n",
       "2  Breakthrough? Based on the story of one patien...   \n",
       "3  The story mostly just rehashes a drug company ...   \n",
       "4  Did the study findings really earn a label of ...   \n",
       "\n",
       "                                      original_title  rating  \\\n",
       "0  Virtual reality to help detect early risk of A...       1   \n",
       "1  Evofem's birth control gel meets main study go...       3   \n",
       "2  How a breakthrough new fertility test is offer...       2   \n",
       "3  J&J says its psoriasis drug superior to Novart...       2   \n",
       "4   Incontinence Drug May Cut Hot Flashes in Brea...       5   \n",
       "\n",
       "                                           reviewers      category  \\\n",
       "0  ['Matt Shipman', 'Doug Campos-Outcalt, MD, MPA...  The Guardian   \n",
       "1  ['Jill U. Adams', 'Susan Molchan, MD, MA', 'Jo...       Reuters   \n",
       "2  ['Gary Schwitzer', 'Karen Carlson, MD', 'Joy V...      ABC News   \n",
       "3  ['Michael Joyce, MD', 'Ishani Ganguli, MD, MPH...       Reuters   \n",
       "4  ['Sue Rochman', 'Karen Carlson, MD', 'Joy Vict...     HealthDay   \n",
       "\n",
       "                               tags  \\\n",
       "0           [\"alzheimer's disease\"]   \n",
       "1                ['contraceptives']   \n",
       "2                   ['infertility']   \n",
       "3                     ['Psoriasis']   \n",
       "4  ['breast cancer', 'hot flashes']   \n",
       "\n",
       "                                         source_link  \\\n",
       "0  https://www.theguardian.com/society/2018/dec/1...   \n",
       "1  https://www.reuters.com/article/us-evofem-stud...   \n",
       "2  https://abcnews.go.com/GMA/Wellness/breakthrou...   \n",
       "3  https://www.reuters.com/article/us-j-j-drug-ps...   \n",
       "4  https://consumer.healthday.com/women-s-health-...   \n",
       "\n",
       "                                             summary  ... Unnamed: 4401  \\\n",
       "0  {'Our Review Summary': 'The story focuses on a...  ...           NaN   \n",
       "1  {'Our Review Summary': 'Reuters reports on a n...  ...           NaN   \n",
       "2  {'Our Review Summary': 'ABC News pursues a sto...  ...           NaN   \n",
       "3  {'Our Review Summary': 'This is a brief news s...  ...           NaN   \n",
       "4  {'Our Review Summary': 'The San Antonio Breast...  ...           NaN   \n",
       "\n",
       "  Unnamed: 4402 Unnamed: 4403 Unnamed: 4404 Unnamed: 4405 Unnamed: 4406  \\\n",
       "0           NaN           NaN           NaN           NaN           NaN   \n",
       "1           NaN           NaN           NaN           NaN           NaN   \n",
       "2           NaN           NaN           NaN           NaN           NaN   \n",
       "3           NaN           NaN           NaN           NaN           NaN   \n",
       "4           NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "  Unnamed: 4407 Unnamed: 4408 Unnamed: 4409 Unnamed: 4410  \n",
       "0           NaN           NaN           NaN           NaN  \n",
       "1           NaN           NaN           NaN           NaN  \n",
       "2           NaN           NaN           NaN           NaN  \n",
       "3           NaN           NaN           NaN           NaN  \n",
       "4           NaN           NaN           NaN           NaN  \n",
       "\n",
       "[5 rows x 4411 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('HealthStoryCSVFileContainingAllData.xlsx') # read the data and save in df \n",
    "df.head() # display some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is a lot of columns so we pick only our target columns\n",
    "df_ = df[['text', 'Q1','Q2','Q3','Q4','Q5','Q6','Q7','Q8','Q9','Q10']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the empty text column rows\n",
    "df_.dropna(subset=['text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the nan values in text\n",
    "df_['text'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clean the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we define functions for clean the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for removal url's\n",
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'link', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### here are some own define stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1092\n"
     ]
    }
   ],
   "source": [
    "my_stopwords = [\"0o\", \"0s\", \"3a\", \"3b\", \"3d\", \"6b\", \"6o\", \"a\", \"a1\", \"a2\", \"a3\", \"a4\", \"ab\", \"able\", \"about\", \"above\", \"abst\", \"ac\", \"accordance\", \"according\", \"accordingly\", \n",
    "                     \"across\", \"act\", \"actually\", \"ad\", \"added\", \"adj\", \"ae\", \"af\", \"after\", \"afterwards\", \"ag\", \"again\", \"ah\", \"aj\", \"al\", \"all\",\n",
    "                      \"also\", \"although\", \"always\", \"am\", \"among\", \"amongst\", \"amoungst\",  \"an\", \"and\", \"announce\", \n",
    "                      \"ao\", \"ap\", \"apparently\", \"appear\",  \"appropriate\", \"to\",\n",
    "                     \"approximately\", \"ar\", \"are\",  \"arise\", \"around\", \"as\", \"a's\", \"aside\",  \"associated\", \"at\", \"au\", \"auth\", \"av\",  \"aw\", \"away\", \"ax\", \"ay\", \n",
    "                     \"az\", \"b\", \"b1\", \"b2\", \"b3\", \"ba\", \"back\", \"bc\", \"bd\", \"be\", \"became\", \"because\", \"become\", \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"begin\", \"beginning\",\n",
    "                     \"beginnings\", \"begins\", \"behind\", \"being\",  \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"bi\", \"bill\", \"biol\", \"bj\", \"bk\", \"bl\", \"bn\", \"both\", \"bottom\", \n",
    "                     \"bp\", \"br\", \"brief\", \"briefly\", \"bs\", \"bt\", \"bu\", \"but\", \"bx\", \"by\", \"c\", \"c1\", \"c2\", \"c3\", \"ca\", \"call\", \"came\",  \"cc\", \"cd\", \"ce\", \n",
    "                      \"cf\", \"cg\", \"ch\", \"ci\", \"cit\", \"cj\", \"cl\", \"cm\", \"c'mon\", \"cn\", \"co\", \"com\", \"come\", \"comes\", \"con\", \"concerning\", \"consequently\",\n",
    "                     \"consider\", \"considering\", \"contain\", \"containing\", \"contains\", \"corresponding\", \"could\", \"course\", \"cp\", \"cq\", \"cr\", \"cry\", \"cs\", \"c's\", \"ct\", \"cu\", \"currently\",\n",
    "                     \"cv\", \"cx\", \"cy\", \"cz\", \"d\", \"d2\", \"da\", \"date\", \"dc\", \"dd\", \"de\", \"definitely\", \"describe\", \"described\", \"despite\", \"detail\", \"df\", \"di\", \"did\",  \"different\", \"dj\",\n",
    "                     \"dk\", \"dl\", \"do\", \"does\", \"doing\", \"downwards\", \"dp\", \"dr\", \"ds\", \"dt\", \"du\", \"due\", \"during\", \"dx\", \"dy\", \"e\", \"e2\", \"e3\", \"ea\", \"each\", \"ec\", \"ed\", \n",
    "                     \"edu\", \"ee\", \"ef\", \"effect\", \"eg\", \"ei\", \"eight\", \"eighty\", \"either\", \"ej\", \"el\", \"eleven\", \"else\", \"elsewhere\", \"em\", \"en\", \"end\", \"ending\", \"entirely\", \"eo\", \"ep\", \"eq\",\n",
    "                     \"er\", \"es\", \"especially\", \"est\", \"et\", \"et-al\", \"etc\", \"eu\", \"ev\", \"every\", \"everybody\", \"everyone\", \"everything\", \"everywhere\", \"ex\", \"exactly\", \"example\", \"ey\", \"f\", \"f2\",\n",
    "                     \"fa\", \"far\", \"fc\", \"few\", \"ff\", \"fi\", \"fifteen\", \"fifth\", \"fify\", \"fill\", \"find\", \"fire\", \"first\", \"five\", \"fix\", \"fj\", \"fl\", \"fn\", \"fo\", \"followed\", \"following\", \"follows\",\n",
    "                     \"for\", \"former\", \"formerly\", \"forth\", \"forty\", \"found\", \"four\", \"fr\", \"from\", \"front\", \"fs\", \"ft\", \"fu\", \"full\", \"further\", \"furthermore\", \"fy\", \"g\", \"ga\", \"gave\", \"ge\", \n",
    "                     \"get\", \"gets\", \"getting\", \"gi\", \"give\", \"given\", \"gives\", \"giving\", \"gj\", \"gl\", \"go\", \"goes\", \"going\", \"gone\", \"got\", \"gotten\", \"gr\", \"greetings\", \"gs\", \"gy\", \"h\", \"h2\", \n",
    "                     \"h3\", \"had\", \"happens\", \"hardly\", \"has\",  \"have\",  \"having\", \"he\", \"hed\", \"he'd\", \"he'll\", \"hello\", \"hence\", \"her\", \"here\", \"hereafter\", \"hereby\", \"herein\", \"heres\",\n",
    "                     \"here's\", \"hereupon\", \"hers\", \"herself\", \"hes\", \"he's\", \"hh\", \"hi\", \"hid\", \"him\", \"himself\", \"his\", \"hither\", \"hj\", \"ho\",  \"hopefully\", \"how\", \"howbeit\", \"however\", \n",
    "                     \"how's\", \"hr\", \"hs\", \"http\", \"hu\", \"hundred\", \"hy\", \"i\", \"i2\", \"i3\", \"i4\", \"i6\", \"i7\", \"i8\", \"ia\", \"ib\", \"ibid\", \"ic\", \"id\", \"i'd\", \"ie\", \"if\", \"ig\",  \"ih\", \"ii\", \"ij\",\n",
    "                     \"il\", \"i'll\", \"im\", \"i'm\", \"in\", \"inasmuch\", \"inc\", \"index\", \"indicate\", \"indicated\", \"indicates\", \"inner\", \"insofar\", \"interest\", \"into\", \"invention\",\n",
    "                     \"inward\", \"io\", \"ip\", \"iq\", \"ir\", \"is\",  \"it\", \"itd\", \"it'd\", \"it'll\", \"its\", \"it's\", \"itself\", \"iv\", \"i've\", \"ix\", \"iy\", \"iz\", \"j\", \"jj\", \"jr\", \"js\", \"jt\", \"ju\", \n",
    "                     \"k\", \"ke\", \"keep\", \"keeps\", \"kept\", \"kg\", \"kj\", \"km\", \"know\", \"known\", \"knows\", \"ko\", \"l\", \"l2\", \"la\", \"largely\",  \"lately\", \"later\", \"latter\", \"latterly\", \"lb\", \"lc\",\n",
    "                     \"le\", \"les\", \"lest\", \"let\", \"lets\", \"let's\", \"lf\", \"line\", \"little\", \"lj\", \"ll\", \"ll\", \"ln\", \"lo\", \"look\", \"looking\", \"looks\", \"los\", \"lr\", \"ls\", \"lt\", \"ltd\",\n",
    "                     \"m\", \"m2\", \"ma\", \"made\", \"mainly\", \"make\", \"makes\", \"me\", \"mean\", \"means\", \"meantime\", \"meanwhile\", \"merely\", \"mg\", \"mill\", \"million\", \"mine\", \n",
    "                     \"ml\", \"mn\", \"mo\", \"more\", \"moreover\", \"move\", \"mr\", \"mrs\", \"ms\", \"mt\", \"mu\", \"mug\",  \"my\", \"myself\", \"n\", \"n2\", \"na\", \"name\", \"namely\", \"nay\", \n",
    "                     \"nc\", \"nd\", \"ne\", \"near\", \"nearly\",\"new\", \"next\", \"ng\", \"ni\", \"nine\", \"ninety\", \"nj\", \"nl\", \"nn\", \"nos\", \"noted\",  \"novel\", \"now\", \"nr\", \"ns\",  \"ny\", \"o\", \"oa\", \"ob\", \n",
    "                     \"obtain\", \"obtained\", \"obviously\", \"oc\", \"od\", \"of\", \"off\", \"often\", \"og\", \"oh\", \"oi\", \"oj\", \"ol\", \"old\", \"om\", \"omitted\", \"on\", \"once\", \"one\", \"ones\",  \"onto\", \n",
    "                     \"oo\", \"op\", \"oq\", \"or\", \"ord\", \"os\", \"ot\", \"other\", \"others\",  \"ou\", \"ought\", \"our\", \"ours\", \"ourselves\",  \"overall\", \"ow\", \"owing\", \"own\", \"ox\", \"oz\", \"p\", \"p1\", \"p2\",\n",
    "                     \"p3\", \"page\", \"pagecount\", \"pages\", \"par\", \"part\", \"particular\", \"particularly\", \"pas\", \"past\", \"pc\", \"pd\", \"pe\", \"per\", \"pf\", \"ph\", \"pi\", \"pj\", \"pk\", \"pl\", \"placed\", \n",
    "                      \"plus\", \"pm\", \"pn\", \"po\", \"pp\", \"pq\", \"pr\", \"predominantly\", \"present\", \"presumably\", \"previously\",  \"promptly\", \"ps\", \"pt\", \"pu\", \"put\", \"py\", \"q\", \"qj\", \"qu\", \"que\",\n",
    "                      \"qv\", \"r\", \"r2\", \"ra\", \"ran\", \"rather\", \"rc\", \"rd\", \"re\", \"readily\",  \"ref\", \"refs\", \"regarding\",  \"related\", \"relatively\", \"research-articl\", \"respectively\",\n",
    "                      \"rf\", \"rh\", \"ri\", \"right\", \"rj\", \"rl\", \"rm\", \"rn\", \"ro\", \"rq\", \"rr\", \"rs\", \"rt\", \"ru\", \"run\", \"rv\", \"ry\", \"s\", \"s2\", \"sa\", \"said\", \"same\", \"saw\", \"say\", \"saying\", \"says\",\n",
    "                     \"sc\", \"sd\", \"se\", \"sec\", \"second\", \"secondly\", \"section\", \"see\", \"seeing\", \"seem\", \"seemed\", \"seeming\", \"seems\", \"seen\", \"self\", \"selves\", \"sensible\", \"sent\", \n",
    "                     \"seven\", \"several\", \"sf\", \"shall\", \"shan\", \"shan't\", \"she\", \"shed\", \"she'd\", \"she'll\", \"shes\", \"she's\", \"should\",  \"should've\",  \"si\", \"side\", \"significant\",\n",
    "                     \"significantly\", \"similar\", \"similarly\", \"since\", \"sincere\", \"six\", \"sixty\", \"sj\", \"sl\", \"slightly\", \"sm\", \"sn\", \"so\", \"some\", \"somebody\", \"somehow\", \"someone\",\n",
    "                     \"somethan\", \"something\", \"sometime\", \"sometimes\", \"somewhat\", \"somewhere\", \"soon\", \"sp\", \"specifically\", \"specified\", \"specify\", \"specifying\", \"sq\", \"sr\", \"ss\", \"st\",\n",
    "                      \"sub\", \"substantially\", \"sup\", \"sy\", \"system\", \"sz\", \"t\", \"t1\", \"t2\", \"t3\", \"take\", \"taken\", \"taking\", \"tb\", \"tc\", \"td\", \"te\", \"tell\", \"ten\", \"tends\", \"tf\", \"th\",  \"that\",\n",
    "                     \"that'll\", \"thats\", \"that's\", \"that've\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\", \"thered\", \"therefore\", \"therein\",\n",
    "                     \"there'll\", \"thereof\", \"therere\", \"theres\", \"there's\", \"thereto\", \"thereupon\", \"there've\", \"these\", \"they\", \"theyd\", \"they'd\", \"they'll\", \"theyre\", \"they're\", \"they've\",\n",
    "                     \"thickv\", \"thin\", \"think\", \"third\", \"this\", \"thorough\", \"thoroughly\", \"those\", \"thou\", \"though\", \"thoughh\", \"thousand\", \"three\", \"throug\", \"through\", \"throughout\", \"thru\", \n",
    "                     \"thus\", \"ti\", \"til\", \"tip\", \"tj\", \"tl\", \"tm\", \"tn\", \"to\",  \"too\", \"took\", \"top\", \"toward\", \"towards\", \"tp\", \"tq\", \"tr\",  \"ts\", \"t's\", \"tt\", \"tv\", \"twelve\", \"twenty\",\n",
    "                     \"twice\", \"two\", \"tx\", \"u\", \"u201d\", \"ue\", \"ui\", \"uj\", \"uk\", \"um\", \"un\", \"under\", \"unto\", \"uo\", \"up\", \"upon\", \"ups\", \"ur\", \"us\", \"use\", \"used\",  \"uses\", \"using\",\"ut\",\n",
    "                     \"v\", \"va\", \"value\", \"various\", \"vd\", \"ve\", \"ve\",  \"via\", \"viz\", \"vj\", \"vo\", \"vol\", \"vols\", \"volumtype\", \"vq\", \"vs\", \"vt\", \"vu\", \"w\", \"wa\", \"want\", \"wants\", \"was\",  \"way\", \"we\", \n",
    "                     \"wed\", \"we'd\",  \"went\", \"were\", \"we're\",  \"we've\", \"what\", \"whatever\", \"what'll\", \"whats\", \"what's\", \"when\", \"whence\", \"whenever\", \"when's\", \"where\", \"whereafter\",\n",
    "                     \"whereas\", \"whereby\", \"wherein\", \"wheres\", \"where's\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whim\", \"whither\", \"who\", \"whod\", \"whoever\", \"whole\", \"who'll\",\n",
    "                     \"whom\", \"whomever\", \"whos\", \"who's\", \"whose\", \"why\", \"why's\", \"wi\", \"widely\", \"will\", \"willing\", \"with\", \"within\",  \"wo\",  \"words\", \"world\", \"would\",  \"www\", \"x\", \"x1\", \"x2\",\n",
    "                     \"x3\", \"xf\", \"xi\", \"xj\", \"xk\", \"xl\", \"xn\", \"xo\", \"xs\", \"xt\", \"xv\", \"xx\", \"y\", \"y2\", \"yes\", \"yet\", \"yj\", \"yl\", \"you\", \"youd\", \"you'd\", \"you'll\", \"your\", \"youre\", \"you're\", \"yours\",\n",
    "                     \"yourself\", \"yourselves\", \"you've\", \"yr\", \"ys\", \"yt\", \"z\", \"zero\", \"zi\", \"zz\",',', '.', '\"', ':', ')', '(', '!', '?', '|', ';', \"'\", '$', '&','/', '[', ']', '>', '%', '=', '#', '*', '+', \n",
    "                '\\\\', '•',  '~', '@', '£', '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›', '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', '“', '★', '”', '–', '●', 'â', '►', '−', \n",
    "                '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', \n",
    "                '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', '▒', '：', '¼', '⊕', '▼', \n",
    "                '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲',\n",
    "                'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', '∙', '）', '↓', '、', '│', '（', '»', \n",
    "                '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', \n",
    "                '¹', '≤', '‡', '√', '«', '»', '´', 'º', '¾', '¡', '§', '£', '₤']\n",
    "# for adding multiple words\n",
    "print(len(my_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(tweet): \n",
    "            \n",
    "    # Special characters\n",
    "    tweet = re.sub(r\"\\x89Û_\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89ÛÒ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89ÛÓ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89ÛÏWhen\", \"When\", tweet)\n",
    "    tweet = re.sub(r\"\\x89ÛÏ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"China\\x89Ûªs\", \"China's\", tweet)\n",
    "    tweet = re.sub(r\"let\\x89Ûªs\", \"let's\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Û÷\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Ûª\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Û\\x9d\", \"\", tweet)\n",
    "    tweet = re.sub(r\"å_\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Û¢\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Û¢åÊ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"fromåÊwounds\", \"from wounds\", tweet)\n",
    "    tweet = re.sub(r\"åÊ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"åÈ\", \"\", tweet)\n",
    "       \n",
    "    tweet = re.sub(r\"Ì©\", \"e\", tweet)\n",
    "    tweet = re.sub(r\"å¨\", \"\", tweet)\n",
    "    \n",
    "    tweet = re.sub(r\"åÇ\", \"\", tweet)\n",
    "    \n",
    "    tweet = re.sub(r\"åÀ\", \"\", tweet)\n",
    "    tweet = re.sub(r'\\b[\\w\\-.]+?@\\w+?\\.\\w{2,4}\\b', 'mentioned', tweet)\n",
    "    tweet = re.sub(r'(http[s]?\\S+)|(\\w+\\.[A-Za-z]{2,4}\\S*)', 'referance', #Replace URLs with 'httpaddr'\n",
    "                     tweet)\n",
    "    tweet = re.sub(r'£|\\$', 'money', tweet) #Replace money symbols with 'moneysymb'\n",
    "    tweet = re.sub(r'\\b(\\+\\d{1,2}\\s)?\\d?[\\-(.]?\\d{3}\\)?[\\s.-]?\\d{3}[\\s.-]?\\d{4}\\b', #Replace phone numbers with 'numbers'\n",
    "                   ' ', tweet)\n",
    "    tweet = re.sub(r'\\d+(\\.\\d+)?', ' ', tweet)  #Replace numbers with 'numbr'\n",
    "    tweet = re.sub(r'[^\\w\\d\\s]', ' ', tweet)\n",
    "    tweet = re.sub(r'\\s+', ' ', tweet)\n",
    "    tweet = re.sub(r'^\\s+|\\s+?$', '', tweet.lower())\n",
    "    \n",
    "    \n",
    "    # Contractions\n",
    "   \n",
    "    tweet = re.sub(r\"he'll\", \"he will\", tweet)\n",
    "    tweet = re.sub(r\"Y'all\", \"You all\", tweet)\n",
    "    tweet = re.sub(r\"Weren't\", \"Were not\", tweet)\n",
    "    tweet = re.sub(r\"Didn't\", \"Did not\", tweet)\n",
    "    tweet = re.sub(r\"they'll\", \"they will\", tweet)\n",
    "    tweet = re.sub(r\"luv\", \"love\", tweet)\n",
    "    tweet = re.sub(r\"they'd\", \"they would\", tweet)\n",
    "    tweet = re.sub(r\"DON'T\", \"DO NOT\", tweet)\n",
    "    tweet = re.sub(r\"That\\x89Ûªs\", \"That is\", tweet)\n",
    "    tweet = re.sub(r\"You\\x89Ûªre\", \"You are\", tweet)\n",
    "    tweet = re.sub(r\"where's\", \"where is\", tweet)\n",
    "    tweet = re.sub(r\"Don\\x89Ûªt\", \"Do not\", tweet)\n",
    "    tweet = re.sub(r\"we'd\", \"we would\", tweet)\n",
    "    tweet = re.sub(r\"i'll\", \"I will\", tweet)\n",
    "    tweet = re.sub(r\"weren't\", \"were not\", tweet)\n",
    "    tweet = re.sub(r\"They're\", \"They are\", tweet)\n",
    "    tweet = re.sub(r\"Can\\x89Ûªt\", \"Cannot\", tweet)\n",
    "    tweet = re.sub(r\"you\\x89Ûªll\", \"you will\", tweet)\n",
    "    tweet = re.sub(r\"I\\x89Ûªd\", \"I would\", tweet)\n",
    "    \n",
    "            \n",
    "    # Character entity references\n",
    "    tweet = re.sub(r\"&gt;\", \">\", tweet)\n",
    "    tweet = re.sub(r\"&lt;\", \"<\", tweet)\n",
    "    tweet = re.sub(r\"&amp;\", \"&\", tweet)\n",
    "    \n",
    "    # Typos, slang and informal abbreviations\n",
    "    tweet = re.sub(r\"w/e\", \"whatever\", tweet)\n",
    "    tweet = re.sub(r\"w/\", \"with\", tweet)\n",
    "   \n",
    "    tweet = re.sub(r\"Ph0tos\", \"Photos\", tweet)\n",
    "    tweet = re.sub(r\"amirite\", \"am I right\", tweet)\n",
    "    tweet = re.sub(r\"exp0sed\", \"exposed\", tweet)\n",
    "  \n",
    "   \n",
    "    tweet = re.sub(r\"Trfc\", \"Traffic\", tweet)\n",
    "    tweet = re.sub(r\"lmao\", \"laughing my ass off\", tweet)   \n",
    "   \n",
    "    tweet = re.sub(r\"e-mail\", \"email\", tweet)\n",
    "    tweet = re.sub(r\"\\s{2,}\", \" \", tweet)\n",
    "    tweet = re.sub(r\"quikly\", \"quickly\", tweet)\n",
    "    \n",
    "    \n",
    "    \n",
    "    tweet = re.sub(r\" iPhone \", \" phone \", tweet)\n",
    "    tweet = re.sub(r\"\\0rs \", \" rs \", tweet) \n",
    "    \n",
    "    tweet = re.sub(r\"ios\", \"operating system\", tweet)\n",
    "  \n",
    "    tweet = re.sub(r\"programing\", \"programming\", tweet)\n",
    "    tweet = re.sub(r\"bestfriend\", \"best friend\", tweet)\n",
    "    \n",
    "    \n",
    "    tweet = re.sub(r\" J K \", \" JK \", tweet)\n",
    "    tweet = re.sub(r\"coronavirus\", \" covid19\", tweet)\n",
    "    tweet = re.sub(r\"covid\", \" covid19\", tweet)\n",
    "    tweet = re.sub(r\"corrona\", \" covid19 \", tweet)\n",
    "    tweet = re.sub(r\"covid1919\", \" covid19 \", tweet)\n",
    "    tweet = re.sub(r\"_\", \"  \", tweet)\n",
    "    \n",
    "    # Urls\n",
    "    tweet = re.sub(r\"https?:\\/\\/t.co\\/[A-Za-z0-9]+\", \"\", tweet)\n",
    "        \n",
    "    # Words with punctuations and special characters\n",
    "    punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\"\n",
    "    for p in punctuations:\n",
    "        tweet = tweet.replace(p, f' {p} ')\n",
    "        \n",
    "    # ... and ..\n",
    "    tweet = tweet.replace('...', ' ... ')\n",
    "    if '...' not in tweet:\n",
    "        tweet = tweet.replace('..', ' ... ') \n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "    return str(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "regular_punct = list(string.punctuation)\n",
    "#all_punct = list(set(regular_punct+ my_stopwords ))\n",
    "def remove_punctuation(text,punct_list=regular_punct):\n",
    "    for punc in punct_list:\n",
    "        if punc in text:\n",
    "            text = text.replace(punc, ' ')\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_remove_words_less_then_3(text):\n",
    "    text = text.split()\n",
    "    text = \" \".join([word for word in text if len(word)>2])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "def nltk_stopword(text, stpwrd=stop_words):\n",
    "    text = text.split()\n",
    "    text = \" \".join([word.lower() for word in text if not word in stpwrd])\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "def stemming_func(text):\n",
    "    text = text.split()\n",
    "    text = \" \".join([ps.stem(word) for word in text])\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ownstopword(text, stpwrd=my_stopwords):\n",
    "    text = text.split()\n",
    "    text = \" \".join([word.lower() for word in text if not word in stpwrd])\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the functions to clean the text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_['text'] = df_['text'].str.lower()# normalized the text by convert to lower case\n",
    "df_['text'] = df_['text'].map(lambda x: str(x)) # convert to string all the text if there any \n",
    "df_['text'] = df_['text'].apply(remove_urls) # remove the urls from the data\n",
    "df_['text'] = df_['text'].apply(clean) # clean the text remove numbers slangs and many mores\n",
    "df_['text'] = df_['text'].apply(nltk_stopword) # remove the nltk stopwords which are predefine\n",
    "df_['text'] = df_['text'].apply(stemming_func) # remove the fisher words it will replace go, going, gone by go same for many\n",
    "df_['text'] = df_['text'].apply(ownstopword) # remove myown stopwords\n",
    "df_['text'] = df_['text'].apply(remove_punctuation) # remove the punctutions\n",
    "df_['text'] = df_['text'].apply(list_to_remove_words_less_then_3) # remove the lenght of words is less then 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Satisfactory           836\n",
       "Not Satisfactory       798\n",
       "Not Applicable           4\n",
       "556307992904478016       1\n",
       "453649552034131008       1\n",
       "470752692759825984       1\n",
       "362922005034577024       1\n",
       "1172378557462429952      1\n",
       "970341728589892992       1\n",
       "553904009506225984       1\n",
       "1186078449427010048      1\n",
       "388687608291020032       1\n",
       "613520444402962048       1\n",
       "887673784026759040       1\n",
       "1091083833812960000      1\n",
       "976527986202676992       1\n",
       "608059742586609024       1\n",
       "1011394464512920064      1\n",
       "203471008492036000       1\n",
       "556191753993460992       1\n",
       "585190125593832960       1\n",
       "1170849548794759936      1\n",
       "253480339316563008       1\n",
       "428014742201192000       1\n",
       "796733126848498944       1\n",
       "Name: Q6, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Q6.value_counts() # check for q6 columns values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df_[df_['Q6'].isin(['Not Satisfactory', 'Satisfactory'])] # remove the unwanted rows which target columns values is missing  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 . connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>11 days 5 hours 41 mins</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Asia/Muscat</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.30.1.3</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>1 month and 18 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_ushah_dth8zb</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>27.01 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>64</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>64</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O_API_Extensions:</td>\n",
       "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.8.5 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------------------------------------\n",
       "H2O_cluster_uptime:         11 days 5 hours 41 mins\n",
       "H2O_cluster_timezone:       Asia/Muscat\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.30.1.3\n",
       "H2O_cluster_version_age:    1 month and 18 days\n",
       "H2O_cluster_name:           H2O_from_python_ushah_dth8zb\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    27.01 Gb\n",
       "H2O_cluster_total_cores:    64\n",
       "H2O_cluster_allowed_cores:  64\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "H2O_API_Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python_version:             3.8.5 final\n",
       "--------------------------  ------------------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init() # intiailizing the environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform each text into a vector of word counts\n",
    "vectorizer = TfidfVectorizer(max_features=1000, max_df = 0.75, \n",
    "                             input=df_['text'].any(),\n",
    "                            ngram_range=(1,2))\n",
    "\n",
    "training_features = vectorizer.fit_transform(df_['text']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Plot the class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_.Q6.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding for target column\n",
    "encoding = {'Not Satisfactory': 0,\n",
    "            'Not Applicable': 0,\n",
    "            'Satisfactory': 1,\n",
    "           }\n",
    "\n",
    "labels = ['Not Satisfactory', 'Satisfactory']\n",
    "           \n",
    "\n",
    "df_['Q6'].replace(encoding, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create dataframe which show features name as column name and in each row contain the counter value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>abnorm</th>\n",
       "      <th>academi</th>\n",
       "      <th>accompani</th>\n",
       "      <th>accord</th>\n",
       "      <th>accord studi</th>\n",
       "      <th>account</th>\n",
       "      <th>accur</th>\n",
       "      <th>achiev</th>\n",
       "      <th>...</th>\n",
       "      <th>youâ</th>\n",
       "      <th>œbut</th>\n",
       "      <th>œif</th>\n",
       "      <th>œit</th>\n",
       "      <th>œitâ</th>\n",
       "      <th>œthe</th>\n",
       "      <th>œthere</th>\n",
       "      <th>œthi</th>\n",
       "      <th>œwe</th>\n",
       "      <th>Q6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059331</td>\n",
       "      <td>0.059662</td>\n",
       "      <td>0.051338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041775</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067704</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024272</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abil       abl  abnorm  academi  accompani    accord  accord studi  \\\n",
       "0   0.0  0.000000     0.0      0.0        0.0  0.000000           0.0   \n",
       "1   0.0  0.000000     0.0      0.0        0.0  0.000000           0.0   \n",
       "2   0.0  0.000000     0.0      0.0        0.0  0.035420           0.0   \n",
       "3   0.0  0.000000     0.0      0.0        0.0  0.041775           0.0   \n",
       "4   0.0  0.024272     0.0      0.0        0.0  0.000000           0.0   \n",
       "\n",
       "    account  accur    achiev  ...  youâ      œbut       œif       œit  œitâ  \\\n",
       "0  0.000000    0.0  0.000000  ...   0.0  0.059331  0.059662  0.051338   0.0   \n",
       "1  0.000000    0.0  0.000000  ...   0.0  0.000000  0.000000  0.000000   0.0   \n",
       "2  0.072041    0.0  0.071088  ...   0.0  0.000000  0.000000  0.000000   0.0   \n",
       "3  0.000000    0.0  0.083843  ...   0.0  0.000000  0.000000  0.000000   0.0   \n",
       "4  0.000000    0.0  0.000000  ...   0.0  0.000000  0.000000  0.000000   0.0   \n",
       "\n",
       "       œthe  œthere  œthi       œwe  Q6  \n",
       "0  0.084778     0.0   0.0  0.047020   0  \n",
       "1  0.000000     0.0   0.0  0.000000   0  \n",
       "2  0.000000     0.0   0.0  0.000000   1  \n",
       "3  0.000000     0.0   0.0  0.067704   0  \n",
       "4  0.000000     0.0   0.0  0.000000   1  \n",
       "\n",
       "[5 rows x 1001 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_to_df_for_h2o = pd.DataFrame(np.array(training_features.A), columns = vectorizer.get_feature_names()) \n",
    "convert_to_df_for_h2o = pd.concat([convert_to_df_for_h2o, df_['Q6'].reset_index(drop=True)], axis=1)\n",
    "convert_to_df_for_h2o.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "train, test = train_test_split(convert_to_df_for_h2o, test_size = 0.2, random_state = 101, stratify=convert_to_df_for_h2o['Q6'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert to H2O datafram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# convert the h2o datafram \n",
    "train_h2o = h2o.H2OFrame(train) \n",
    "test_h2o = h2o.H2OFrame(test)\n",
    "train_h2o['Q6'] = train_h2o['Q6'].asfactor() # specify the target column\n",
    "test_h2o['Q6'] = test_h2o['Q6'].asfactor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml = H2OAutoML(max_models=20, seed = 10, nfolds = 5) # we train top 20 models with cross validation of k-fold = 5\n",
    "x = vectorizer.get_feature_names() # tell the model the features name \n",
    "y = 'Q6' # specify the target column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |████████████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                           </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">   aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">     mse</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_AutoML_20201115_222040</td><td style=\"text-align: right;\">0.709634</td><td style=\"text-align: right;\"> 0.624987</td><td style=\"text-align: right;\">0.706336</td><td style=\"text-align: right;\">              0.361827</td><td style=\"text-align: right;\">0.466111</td><td style=\"text-align: right;\">0.217259</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_AutoML_20201115_222040   </td><td style=\"text-align: right;\">0.709215</td><td style=\"text-align: right;\"> 0.625056</td><td style=\"text-align: right;\">0.703991</td><td style=\"text-align: right;\">              0.386985</td><td style=\"text-align: right;\">0.466191</td><td style=\"text-align: right;\">0.217334</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20201115_222040_model_1         </td><td style=\"text-align: right;\">0.703841</td><td style=\"text-align: right;\"> 0.627944</td><td style=\"text-align: right;\">0.699024</td><td style=\"text-align: right;\">              0.341768</td><td style=\"text-align: right;\">0.467719</td><td style=\"text-align: right;\">0.218761</td></tr>\n",
       "<tr><td>GBM_4_AutoML_20201115_222040                       </td><td style=\"text-align: right;\">0.689188</td><td style=\"text-align: right;\"> 0.639918</td><td style=\"text-align: right;\">0.683377</td><td style=\"text-align: right;\">              0.385142</td><td style=\"text-align: right;\">0.473335</td><td style=\"text-align: right;\">0.224046</td></tr>\n",
       "<tr><td>GBM_3_AutoML_20201115_222040                       </td><td style=\"text-align: right;\">0.688301</td><td style=\"text-align: right;\"> 0.640159</td><td style=\"text-align: right;\">0.684949</td><td style=\"text-align: right;\">              0.375036</td><td style=\"text-align: right;\">0.473471</td><td style=\"text-align: right;\">0.224174</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20201115_222040_model_2         </td><td style=\"text-align: right;\">0.686846</td><td style=\"text-align: right;\"> 0.64686 </td><td style=\"text-align: right;\">0.674985</td><td style=\"text-align: right;\">              0.403941</td><td style=\"text-align: right;\">0.475711</td><td style=\"text-align: right;\">0.226301</td></tr>\n",
       "<tr><td>GBM_5_AutoML_20201115_222040                       </td><td style=\"text-align: right;\">0.684295</td><td style=\"text-align: right;\"> 0.638785</td><td style=\"text-align: right;\">0.689599</td><td style=\"text-align: right;\">              0.457085</td><td style=\"text-align: right;\">0.473283</td><td style=\"text-align: right;\">0.223997</td></tr>\n",
       "<tr><td>XGBoost_grid__1_AutoML_20201115_222040_model_2     </td><td style=\"text-align: right;\">0.678536</td><td style=\"text-align: right;\"> 0.644183</td><td style=\"text-align: right;\">0.657766</td><td style=\"text-align: right;\">              0.413188</td><td style=\"text-align: right;\">0.475543</td><td style=\"text-align: right;\">0.226141</td></tr>\n",
       "<tr><td>XGBoost_3_AutoML_20201115_222040                   </td><td style=\"text-align: right;\">0.676644</td><td style=\"text-align: right;\"> 0.68357 </td><td style=\"text-align: right;\">0.665674</td><td style=\"text-align: right;\">              0.408519</td><td style=\"text-align: right;\">0.487475</td><td style=\"text-align: right;\">0.237631</td></tr>\n",
       "<tr><td>GBM_2_AutoML_20201115_222040                       </td><td style=\"text-align: right;\">0.674719</td><td style=\"text-align: right;\"> 0.649378</td><td style=\"text-align: right;\">0.661907</td><td style=\"text-align: right;\">              0.456225</td><td style=\"text-align: right;\">0.477539</td><td style=\"text-align: right;\">0.228044</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.train(x=x, y=y, training_frame= train_h2o) # training \n",
    "aml.leaderboard # show the top 10 models performance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsBinomialGLM: stackedensemble\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.23238963936805387\n",
      "RMSE: 0.4820680858219655\n",
      "LogLoss: 0.6571411809311842\n",
      "Null degrees of freedom: 319\n",
      "Residual degrees of freedom: 314\n",
      "Null deviance: 443.5019079753976\n",
      "Residual deviance: 420.5703557959579\n",
      "AIC: 432.5703557959579\n",
      "AUC: 0.6611504044390606\n",
      "AUCPR: 0.6452292383412186\n",
      "Gini: 0.3223008088781212\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3114466604335245: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.707</td>\n",
       "      <td>(111.0/157.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.092</td>\n",
       "      <td>(15.0/163.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>61.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>0.3937</td>\n",
       "      <td>(126.0/320.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0      1   Error            Rate\n",
       "0      0  46.0  111.0   0.707   (111.0/157.0)\n",
       "1      1  15.0  148.0   0.092    (15.0/163.0)\n",
       "2  Total  61.0  259.0  0.3937   (126.0/320.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.311447</td>\n",
       "      <td>0.701422</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.219581</td>\n",
       "      <td>0.845588</td>\n",
       "      <td>294.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.421592</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.421592</td>\n",
       "      <td>0.631250</td>\n",
       "      <td>192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.806063</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.144167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>311.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.874754</td>\n",
       "      <td>0.993631</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.421592</td>\n",
       "      <td>0.264362</td>\n",
       "      <td>192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.491501</td>\n",
       "      <td>0.617834</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.421592</td>\n",
       "      <td>0.629362</td>\n",
       "      <td>192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.874754</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.874754</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.093427</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>313.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.144167</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>311.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.874754</td>\n",
       "      <td>0.993631</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.874754</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.093427</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>313.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.144167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>311.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold       value    idx\n",
       "0                        max f1   0.311447    0.701422  256.0\n",
       "1                        max f2   0.219581    0.845588  294.0\n",
       "2                  max f0point5   0.421592    0.636364  192.0\n",
       "3                  max accuracy   0.421592    0.631250  192.0\n",
       "4                 max precision   0.806063    0.916667   11.0\n",
       "5                    max recall   0.144167    1.000000  311.0\n",
       "6               max specificity   0.874754    0.993631    0.0\n",
       "7              max absolute_mcc   0.421592    0.264362  192.0\n",
       "8    max min_per_class_accuracy   0.491501    0.617834  160.0\n",
       "9   max mean_per_class_accuracy   0.421592    0.629362  192.0\n",
       "10                      max tns   0.874754  156.000000    0.0\n",
       "11                      max fns   0.874754  163.000000    0.0\n",
       "12                      max fps   0.093427  157.000000  313.0\n",
       "13                      max tps   0.144167  163.000000  311.0\n",
       "14                      max tnr   0.874754    0.993631    0.0\n",
       "15                      max fnr   0.874754    1.000000    0.0\n",
       "16                      max fpr   0.093427    1.000000  313.0\n",
       "17                      max tpr   0.144167    1.000000  311.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 50.94 %, avg score: 50.19 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.857284</td>\n",
       "      <td>1.472393</td>\n",
       "      <td>1.472393</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.867026</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.867026</td>\n",
       "      <td>0.018405</td>\n",
       "      <td>0.018405</td>\n",
       "      <td>47.239264</td>\n",
       "      <td>47.239264</td>\n",
       "      <td>0.012035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.021875</td>\n",
       "      <td>0.826956</td>\n",
       "      <td>1.963190</td>\n",
       "      <td>1.682734</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.838090</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.854625</td>\n",
       "      <td>0.018405</td>\n",
       "      <td>0.036810</td>\n",
       "      <td>96.319018</td>\n",
       "      <td>68.273444</td>\n",
       "      <td>0.030440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.815508</td>\n",
       "      <td>1.963190</td>\n",
       "      <td>1.766871</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.818140</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.843679</td>\n",
       "      <td>0.018405</td>\n",
       "      <td>0.055215</td>\n",
       "      <td>96.319018</td>\n",
       "      <td>76.687117</td>\n",
       "      <td>0.048845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.040625</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>1.308793</td>\n",
       "      <td>1.661161</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.808710</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.835609</td>\n",
       "      <td>0.012270</td>\n",
       "      <td>0.067485</td>\n",
       "      <td>30.879346</td>\n",
       "      <td>66.116092</td>\n",
       "      <td>0.054746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.789273</td>\n",
       "      <td>0.654397</td>\n",
       "      <td>1.472393</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.800814</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.829085</td>\n",
       "      <td>0.006135</td>\n",
       "      <td>0.073620</td>\n",
       "      <td>-34.560327</td>\n",
       "      <td>47.239264</td>\n",
       "      <td>0.048142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.758805</td>\n",
       "      <td>1.104294</td>\n",
       "      <td>1.288344</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.768313</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.798699</td>\n",
       "      <td>0.055215</td>\n",
       "      <td>0.128834</td>\n",
       "      <td>10.429448</td>\n",
       "      <td>28.834356</td>\n",
       "      <td>0.058771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.746251</td>\n",
       "      <td>1.226994</td>\n",
       "      <td>1.267894</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.751711</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.783036</td>\n",
       "      <td>0.061350</td>\n",
       "      <td>0.190184</td>\n",
       "      <td>22.699387</td>\n",
       "      <td>26.789366</td>\n",
       "      <td>0.081904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.714564</td>\n",
       "      <td>1.717791</td>\n",
       "      <td>1.380368</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.729616</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.769681</td>\n",
       "      <td>0.085890</td>\n",
       "      <td>0.276074</td>\n",
       "      <td>71.779141</td>\n",
       "      <td>38.036810</td>\n",
       "      <td>0.155055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.640157</td>\n",
       "      <td>1.226994</td>\n",
       "      <td>1.329243</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.677729</td>\n",
       "      <td>0.677083</td>\n",
       "      <td>0.739031</td>\n",
       "      <td>0.122699</td>\n",
       "      <td>0.398773</td>\n",
       "      <td>22.699387</td>\n",
       "      <td>32.924335</td>\n",
       "      <td>0.201321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.559080</td>\n",
       "      <td>1.104294</td>\n",
       "      <td>1.273006</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.602187</td>\n",
       "      <td>0.648438</td>\n",
       "      <td>0.704820</td>\n",
       "      <td>0.110429</td>\n",
       "      <td>0.509202</td>\n",
       "      <td>10.429448</td>\n",
       "      <td>27.300613</td>\n",
       "      <td>0.222578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.492066</td>\n",
       "      <td>1.042945</td>\n",
       "      <td>1.226994</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.525087</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.668873</td>\n",
       "      <td>0.104294</td>\n",
       "      <td>0.613497</td>\n",
       "      <td>4.294479</td>\n",
       "      <td>22.699387</td>\n",
       "      <td>0.231331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.421975</td>\n",
       "      <td>1.104294</td>\n",
       "      <td>1.206544</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.460827</td>\n",
       "      <td>0.614583</td>\n",
       "      <td>0.634199</td>\n",
       "      <td>0.110429</td>\n",
       "      <td>0.723926</td>\n",
       "      <td>10.429448</td>\n",
       "      <td>20.654397</td>\n",
       "      <td>0.252589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.368310</td>\n",
       "      <td>0.736196</td>\n",
       "      <td>1.139351</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.392646</td>\n",
       "      <td>0.580357</td>\n",
       "      <td>0.599691</td>\n",
       "      <td>0.073620</td>\n",
       "      <td>0.797546</td>\n",
       "      <td>-26.380368</td>\n",
       "      <td>13.935145</td>\n",
       "      <td>0.198820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.324003</td>\n",
       "      <td>0.981595</td>\n",
       "      <td>1.119632</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.344648</td>\n",
       "      <td>0.570312</td>\n",
       "      <td>0.567811</td>\n",
       "      <td>0.098160</td>\n",
       "      <td>0.895706</td>\n",
       "      <td>-1.840491</td>\n",
       "      <td>11.963190</td>\n",
       "      <td>0.195069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.239334</td>\n",
       "      <td>0.552147</td>\n",
       "      <td>1.056578</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.279020</td>\n",
       "      <td>0.538194</td>\n",
       "      <td>0.535723</td>\n",
       "      <td>0.055215</td>\n",
       "      <td>0.950920</td>\n",
       "      <td>-44.785276</td>\n",
       "      <td>5.657805</td>\n",
       "      <td>0.103786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.093427</td>\n",
       "      <td>0.490798</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.197851</td>\n",
       "      <td>0.509375</td>\n",
       "      <td>0.501936</td>\n",
       "      <td>0.049080</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-50.920245</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0       1                  0.012500         0.857284  1.472393   \n",
       "1       2                  0.021875         0.826956  1.963190   \n",
       "2       3                  0.031250         0.815508  1.963190   \n",
       "3       4                  0.040625         0.803371  1.308793   \n",
       "4       5                  0.050000         0.789273  0.654397   \n",
       "5       6                  0.100000         0.758805  1.104294   \n",
       "6       7                  0.150000         0.746251  1.226994   \n",
       "7       8                  0.200000         0.714564  1.717791   \n",
       "8       9                  0.300000         0.640157  1.226994   \n",
       "9      10                  0.400000         0.559080  1.104294   \n",
       "10     11                  0.500000         0.492066  1.042945   \n",
       "11     12                  0.600000         0.421975  1.104294   \n",
       "12     13                  0.700000         0.368310  0.736196   \n",
       "13     14                  0.800000         0.324003  0.981595   \n",
       "14     15                  0.900000         0.239334  0.552147   \n",
       "15     16                  1.000000         0.093427  0.490798   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          1.472393       0.750000  0.867026                  0.750000   \n",
       "1          1.682734       1.000000  0.838090                  0.857143   \n",
       "2          1.766871       1.000000  0.818140                  0.900000   \n",
       "3          1.661161       0.666667  0.808710                  0.846154   \n",
       "4          1.472393       0.333333  0.800814                  0.750000   \n",
       "5          1.288344       0.562500  0.768313                  0.656250   \n",
       "6          1.267894       0.625000  0.751711                  0.645833   \n",
       "7          1.380368       0.875000  0.729616                  0.703125   \n",
       "8          1.329243       0.625000  0.677729                  0.677083   \n",
       "9          1.273006       0.562500  0.602187                  0.648438   \n",
       "10         1.226994       0.531250  0.525087                  0.625000   \n",
       "11         1.206544       0.562500  0.460827                  0.614583   \n",
       "12         1.139351       0.375000  0.392646                  0.580357   \n",
       "13         1.119632       0.500000  0.344648                  0.570312   \n",
       "14         1.056578       0.281250  0.279020                  0.538194   \n",
       "15         1.000000       0.250000  0.197851                  0.509375   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate       gain  \\\n",
       "0           0.867026      0.018405                 0.018405  47.239264   \n",
       "1           0.854625      0.018405                 0.036810  96.319018   \n",
       "2           0.843679      0.018405                 0.055215  96.319018   \n",
       "3           0.835609      0.012270                 0.067485  30.879346   \n",
       "4           0.829085      0.006135                 0.073620 -34.560327   \n",
       "5           0.798699      0.055215                 0.128834  10.429448   \n",
       "6           0.783036      0.061350                 0.190184  22.699387   \n",
       "7           0.769681      0.085890                 0.276074  71.779141   \n",
       "8           0.739031      0.122699                 0.398773  22.699387   \n",
       "9           0.704820      0.110429                 0.509202  10.429448   \n",
       "10          0.668873      0.104294                 0.613497   4.294479   \n",
       "11          0.634199      0.110429                 0.723926  10.429448   \n",
       "12          0.599691      0.073620                 0.797546 -26.380368   \n",
       "13          0.567811      0.098160                 0.895706  -1.840491   \n",
       "14          0.535723      0.055215                 0.950920 -44.785276   \n",
       "15          0.501936      0.049080                 1.000000 -50.920245   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0         47.239264            0.012035  \n",
       "1         68.273444            0.030440  \n",
       "2         76.687117            0.048845  \n",
       "3         66.116092            0.054746  \n",
       "4         47.239264            0.048142  \n",
       "5         28.834356            0.058771  \n",
       "6         26.789366            0.081904  \n",
       "7         38.036810            0.155055  \n",
       "8         32.924335            0.201321  \n",
       "9         27.300613            0.222578  \n",
       "10        22.699387            0.231331  \n",
       "11        20.654397            0.252589  \n",
       "12        13.935145            0.198820  \n",
       "13        11.963190            0.195069  \n",
       "14         5.657805            0.103786  \n",
       "15         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pref = aml.leader.model_performance(test_h2o) # validation the best model on test data\n",
    "pref # display the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: [[0.42159213865884837, 0.63125]]\n",
      "AUC score: 0.6611504044390606\n",
      "F1 score: [[0.3114466604335245, 0.7014218009478673]]\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score:', pref.accuracy()) # accuracy of the best model over test data\n",
    "print('AUC score:', pref.auc())  # area under cure of the best model over test data\n",
    "print('F1 score:', pref.F1()) # f1 score of the best model over the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
